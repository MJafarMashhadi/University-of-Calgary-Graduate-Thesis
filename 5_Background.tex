\chapter{Background and Related Work} \label{sec:background}
Unlike the numerous techniques in the literature for behavior model inference \cite{lang1998results, walkinshaw2016inferring, Lo2007Mining, dallmeier2006mining} which abstract a set of execution traces into states, my approach requires consuming a multivariate time-series and detect the state changes across time and predict the exact state labels. Thus, in this section, we briefly explain the two main sets of relevant existing techniques for ``Change Point Detection'' and ``State Prediction'' in time-series that can serve as background for my approach.  

\section{State Model Inference}
\hl{Dynamic model inference as a sub-field of specification mining is a vast field of research.
There are model inference techniques for several different types of models that can be made for software systems, for example Damas et al. } infer message sequence charts \cite{damas2005generating}, Lo et al. try inferring LSCs \cite{Lo2007Mining}, and Lemieux et al. explore mining LTLs \cite{lemieux2015general}. However state models are a useful, popular, and widely researched type of model to infer. Two major categories of state models are finite state machines (FSM), and their extended version: EFSM. Extended Finite State Machines, are special kind of state machines that have conditional expressions called ``transition guards'' on their transitions \cite{lorenzoli2008automatic}. A state transition can only happen if the transition guard evaluates as true.

Roughly speaking, dynamic EFSM inference algorithms generally take a trace of ``events'' (along with perhaps some variable values) as their input \cite{walkinshaw2016inferring} to infer a generalized finite state machine. They use the events to find the state transitions and the values for detecting invariants and generating the guard conditions on the transitions. 
k Tails, Gk Tail, EDSM, and MINT are examples of these algorithms, each improving upon the previous one \cite{biermann1972synthesis, lorenzoli2008automatic, lang1998results, walkinshaw2016inferring}.  % Merge paragraphs together
The data that is generated in software run time is quite varied; It can range from the logs, to function calls, to network packets, to syscalls, and so forth. There are several aspects to be considered for this matter: what kind of data is needed, how are they going to be collected, what kind of model we are looking to have, and how are they going to be used in model inference. 

Walkinshaw et al., proposed an algorithm and developed a tool for state model inference \cite{walkinshaw2016inferring}. Their work is based on previous endeavors on state merging algorithms such as gk-tail and k-tails \cite{lorenzoli2008automatic, biermann1972synthesis}. \hl{Their approach requires two collections of ordered events as input: a collection of positive examples which are events generated during a successful execution of the software as well as a set of negative examples. Each event there, is a function call; the log contains the list of functions that were called along with their parameters.}

K-Tails algorithm \cite{biermann1972synthesis} generates FSMs from execution traces which can be flexible in form. gk-tail takes it to the next level by adding transition guards to the state machine, making it an EFSM \cite{lorenzoli2008automatic}. 
The input to gk-tail should include parameter values to be used for inferring the transition guards using Daikon \cite{ernst2007daikon}. 

\hl{As mentioned earlier, the input to dynamic model inference techniques can be of many different types. Other than the above examples that take function call logs as the execution trace, there are many other studies that used different types of input. For example, In Synoptic} \cite{schneider2010synoptic} \hl{the communications in a distributed system is being modeled as an automata and the events are the logs generated by its components.}
Howar et al. \cite{howar2012inferring}  generate state models, with the events being high level actions such as `user registered` and `user logged in'.

Krka et al., performed an empirical study on 4 different categories of model inference algorithms to figure out what makes each group of methods more effective \cite{krka2014automatic}. Beschastnikh et al., proposed a method to mine invariants from partially ordered logs from concurrent/distributed systems \cite{beschastnikh2011mining}. Invariants can be used to augment state models \cite{beschastnikh2014inferring, beschastnikh2011leveraging}. Groz et al., use machine learning to heuristically infer state machine models of a un-resettable black-box system \cite{groz2018revisiting}, however a significant difference between my method and theirs is that their method still relies on discrete events (such as HTTP request and responses) while my method does not assume that the input and outputs contain any kind of ``events'' happening at certain times. My method aims to search for such events as change points in a continuous stream of data as time series. 
Papadopoulos et al., proposed an active learning method (with repeated interaction with a user) to model a black-box system and generate test data \cite{Papadopoulos2015}. 
In \cite{jafar2019interactive} a semi-interactive method for inferring state machines is proposed. It requires instrumenting the source code (white-box) and performs dynamic analysis of the system under study.

\section{Automated Test Generation} \hl{new subsection in BKG}
Testing software can be automated using the state of practice tools such as JUnit and Pytest. In automated testing, a developer writes test code that runs their code, gives it inputs and compares outputs with the expected outputs to verify if the program is behaving correctly. 
Automated testing is widely researched and ubiquitously used in the industry. 

The next level in test automation is automated test generation, that is having a code that can automatically generate test code \cite{ibrahim2007automatic}. 
There are several approaches in the literature for tackling this problem. 
Model-based testing approaches use inferred models or hand crafted models to automate some tasks in testing. For example, Papadopoulos et al.'s method \cite{Papadopoulos2015} can generate test data using active learning. A similar paper is the work by Volpato and Tretmans \cite{volpato2014active} that use state models for test generation.
Search-based testing approaches, use well-known search algorithms such as evolutionary algorithms to generate test cases and test data. Random testing approaches generate randomized input data for testing.
For example, evo-suite is a widely used test generation tool that uses evolutionary algorithms under the hood \cite{fraser2011evosuite} to generate unit tests for Java applications. DART and Randoop \cite{Godefroid2005DART, pacheco2007randoop} generate random data to test the software. Feedback-directed random test generation is an step of improvement over na√Øve random test generation techniques \cite{pacheco2007feedback}.
Fuzz testing is a similar approach to random test generation. DeepFuzz uses fuzzing to generate syntactically valid C code to catch bugs in C compilers \cite{liu2019deepfuzz}. Fairfuzz \cite{lemieux2018fairfuzz} monitors branch coverage of generated inputs to guide fuzzing in a way that rare branches are also covered adequately.


\section{Change Point Detection}
A fundamental tool in time-series data analysis is Change Point Detection (CPD). It refers to the task of finding points of abrupt change in the underlying statistical model or its parameters that could be a result of a state transition \cite{aminikhanghahi2017survey}. It is a well-studied subject due to its wide range of applications \cite{basseville1993detection}.
%An auto-pilot software detects changes in the inputs and makes adjustments to its outputs in order to hold some invariants (predefined rules). 
%For example, if the auto-pilot is in the ``hold altitude'' mode, it monitors the altimeter's readings and when it goes out of the acceptable range, proportionate adjustments to the throttle or the nose pitch will be made to get it back to the desired altitude. This is basically how a typical feedback loop controller, such as PID or its variations, work \cite{feedbacksystemsBook}.
%When the auto-pilot's state changed from ``hold altitude'' state to ``descend to X ft'' state, the set of invariants that the auto-pilot is trying to hold are changed. It means the auto-pilot's reactions to variations in inputs will be different. In this example, a decreasing altimeter reading will not trigger an increase in the throttle anymore.
%With all these in mind, it seems plausible to use CPD algorithms to detect when states change by looking at the inputs and outputs of the auto-pilot and how they are related.
A multitude of statistical and algorithmic methods have been tried to tackle several variations of CPD problem \cite{chen2011parametric, hasan2014information, hsu1982bayesian, lee2017implicit, oh2002analyzing, ramos2016anomalies, chowdhury2012bayesian, reeves2007review, rosenfield2010change, wang2011non, xie2013sequential, yamanishi2004line, Lavielle1999}; many of which perform effectively on a subset of CPD problems with some assumptions. The assumptions can be of various types. For example, one may assume the time series has only one input variable (univariate) \cite{fryzlewicz2014wild}, there is only one changing point \cite{bai1998testing}, or the number of change points is known beforehand \cite{lavielle2005using}, or they might assume some statistical properties on the data \cite{chen2011parametric, takeuchi2006unifying, ide2007change}. These are limiting factors, since many of these assumptions do not necessarily hold in this case. CPD techniques are categorized into two main groups: a) online methods that process the data in real-time and b) offline methods that start processing the data after receiving all the values \cite{Truong2018ChangePointSurvey}. Since my model inference use case of CPD can afford waiting to collect all historical training data, I  considered only the offline techniques. %But we limit ourselves to multivariate techniques with no statistical assumptions on the distribution of input data that can work with unknown number of change points. 
%, listed in a recent CPD survey \cite{Truong2018ChangePointSurvey}.

Ives and Dakos utilized locally linear models and used statistical significance test to determine at which point the changes in model parameters are large enough to signal a change in the state \cite{Ives2012}. Blythe et al., used subspace analysis to reduce data dimensionality to keep the most non-stationary dimensions. This process helps detecting change points more effectively \cite{Blythe2012}.
Several techniques have used penalty functions to find models that best fit each segment of the signal \cite{Lavielle1999, lavielle2005using, keshavarz2018optimal, pein2017heterogeneous, khan2019deep}. 
Desobry et al., and Hido et al., proposed methods to indirectly use classifiers such as SVM to detect change points \cite{desobry2005online, hido2008unsupervised, Khan2019thesis}. I applied their approach on the data in hand in early stages of the research but it could not perform as others.
Lee et al., trained deep auto encoder networks that learns latent features in the data to detect change points \cite{Lee2018TimeSeriesSegmentation}. Ebrahimzadeh et al., proposed what they call a pyramid recurrent neural network architecture, which is resilient to missing to detect patterns that are warped in time \cite{Ebrahimzadeh2019}.
There is also a family of methods based on Bayesian models that focus on finding changes in parameters of underlying distributions of the data \cite{Lee2018TimeSeriesSegmentation, adams2007bayesian, bai1997estimation, barry1993bayesian, erdman2008fast, ray2002bayesian}. 

Making assumptions about the data such as its distribution or the distribution of change points across the time and relying on basic statistical properties are the two major short comings of traditional CPD methods \cite{Lee2018TimeSeriesSegmentation}, which my proposed approach has overcome.


In general, CPD algorithms consist of two major components: a) the search method and b) the cost function \cite{Truong2018ChangePointSurvey}.
Search methods are either exact or approximate. For instance, Pelt is the most efficient exact search method in the CPD literature, which uses pruning \cite{killick2012optimal}. Approximate methods include window-based \cite{basseville1993detection}, bottom-up \cite{keogh2001online}, binary segmentation \cite{scott1974cluster}, and more. In the window-based segmentation a sliding window is rolled over the data and then sum of costs of left and right half-windows is subtracted from the cost of the whole window. When the difference gets significantly high it means that the discrepancy between left and right half of the window is high and therefore a change point probably lies right in the middle of the window. In the bottom-up method, the input signal is split into multiple smaller parts, then using a similarity measure adjacent segments are merged until no more merges are feasible. The binary segmentation method finds one change point and splits the input into two parts around that point and then recursively applies the same method on each part.

The cost functions are also quite various, from simply subtracting each point from the mean to much more complex metrics, such as auto-regressive cost functions \cite{angelosante2012group}, and kernel-based cost functions. Kernel-based costs can have a wide variety, since the kernel function can be almost arbitrary, however a handful of them such as linear and Gaussian kernels are among the most popular ones \cite{Truong2018ChangePointSurvey}.

In the context of this thesis, we need a CPD method with no assumption on data distribution, number of change points, etc. 
In addition, my CPD method should work on multivariate data, and be able to capture non-linear relations between signals. 
It also needs to be resilient to time lags between an input signal change and its effect on the output signal (and the systems state). There is no traditional CPD algorithms that covers all these requirements.
Therefore, I propose a novel CPD techniques that is based on Hybrid DNNs and compare it with several existing CPD techniques as comparison baselines, which are explained in details in section~\ref{sec:experiment}.   


\section{Convolutional and Recurrent Neural Networks}
In both my problems (CPD and state classification), one can see that the changes in signals are more informative than their absolute values. Therefore, applying a derivation operation (or more generally a gradient) seems like necessary, at some point in the processing. Farid and Simoncelli listed some discrete derivation kernels in their study \cite{Farid2004}, but to have a more generalized and more flexible notion of discrete derivatives, convolutions seems like a better choice to apply. 
Nowadays, applying convolutional filters on signals is pretty much a standard process in signal processing studies that leverage deep learning \cite{morales2016deep, zeng2014convolutional, yang2015deep}. Convolutional neural networks (CNNs) can learn to find features in a multidimensional input while being less sensitive to the exact location of the feature in the input \cite{lecun2015deep}. In the forward pass of a convolutional layer, multiple filters are applied to the input. %Each convolutional layer can learn and apply multiple filters, 
It means that in a trained neural net, multiple features can be leaned in one single convolutional layer.

Recurrent neural networks (RNN) have shown great performance in analysing sequential data such as machine translation, time-series prediction, and time-series classification \cite{cho2014learning, zhang2000predicting, wang2017time, murad2017deep, yang2015deep, Ordonez2016}. RNNs can capture long-term temporal dependencies which is quite useful to solve this problem. \cite{Che2018} For example, they might learn that ``climb'' state in a UAV auto-pilot usually follows ``take off''. Therefore, while it is outputting ``take off'' it anticipates what the next state will probably be and as soon as its input features start shifting, it detects the onset of a state change. It will help the model to better predict the system's behavior and be quicker to detect state changes in a way that could hardly be achieved with classic methods.
Therefore, in this thesis, I combine the CNNs and RNNs to create what is known as a hybrid deep neural network \cite{wang2017time} to use for both CPD and state classification problems, in this context.  
% http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf


\section{Using Deep Learning on Time Series Data} \label{sec:related_work_har}
Human activity recognition (HAR) is a well researched task which is quite relevant to the problem of black-box model inference. In HAR, just like in this context, a multivariate time series data is created from various sensors on a human body. 
The goal is to figure out what was the activity that human was performing in different time intervals. The sensors can be body worn accelerometers, or more generic sensors such as the ones found in a smart watch or a smartphone. 
Murad et al., \cite{murad2017deep} have shown deep RNNs outperform fully convolutional networks and deep belief networks in HAR task.
Hybrid models are the combination of some deep architectures \cite{wang2019deep}, such as a CNN + RNN or a CNN + a fully connected net. Morales et al., have shown the former preforms better than the latter in HAR \cite{morales2016deep}. Yao et al., \cite{deepsense} introduced a CNN + RNN architecture that outperforms the state of the art both in classification and in regression tasks. Similar results have been shown in other works such as \cite{Ordonez2016, singh2017transforming, zheng2016exploiting}, as well.

Another related topic here is the time series classification. However, time series classification techniques often output only one label classifying entire data, thus not applicable in this context. 
What is more related to my problem is called ``segmentation'', using the computer vision terminology (not be confused with time series segmentation, such as \cite{lemire2007better}). 
U-net is one of the promising auto-encoder architectures for image segmentation \cite{ronneberger2015u}. Perslev et al., developed a similar idea for time-series to capture long-term dependencies and called it U-time \cite{perslev2019u}. It is fully convolutional and does not use memory cells (recurrent cells). 
A fully convolutional model can perform very well, since convolutions operate locally and image segments are large chunks of pixels in the 2D space and capturing local features using neighbouring pixels is quite useful. However, it cannot necessarily be as powerful on a more limited 1D data of time-series with different characteristics from an image. 
U-time's design is optimized for the task of sleep phase detection, which does not have very clear boundaries between states and also the state changes are quite infrequent. Therefore, the same method does not necessarily generalize to tasks such as mine, where I cannot make assumptions about frequency of state changes.


